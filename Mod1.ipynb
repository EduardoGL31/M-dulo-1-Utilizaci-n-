{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "9cHqg8m2DUlL",
        "outputId": "5e871c3a-c28c-4555-8dc4-cbd346d8a257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 5,484 B/110\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 38.8 kB/110\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 72.1 kB/110\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to ppa.launc\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.52\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,384 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,012 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,184 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [557 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,453 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,278 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,410 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n",
            "Fetched 12.0 MB in 3s (3,482 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=c7e743fe4f191eba71a56da387dd2b05810b8d478412828a0a7085643d86df2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.5.0-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la funcionalidad de Pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark_session = SparkSession.builder.appName('Modulo_1').getOrCreate()\n",
        "spark_session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "RWWmvhRV9c20",
        "outputId": "281bcfc5-f365-432a-b77e-7ccea519a5f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ca15630c910>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://58aa08bd22a4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Modulo_1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso de un dataset sobre cáncer de mama\n",
        "df_spark = spark_session.read.csv('sample_data/cancer.csv', header=True, inferSchema=True)\n",
        "# Vemos nuestros datos en un dataframe de pyspark\n",
        "df_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MtyOaATEI2l",
        "outputId": "998ee2ea-6cdd-46a1-e907-7307ab221682"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+\n",
            "|      id|diagnosis|radius_mean|texture_mean|perimeter_mean|area_mean|smoothness_mean|compactness_mean|concavity_mean|concave points_mean|symmetry_mean|fractal_dimension_mean|radius_se|texture_se|perimeter_se|area_se|smoothness_se|compactness_se|concavity_se|concave points_se|symmetry_se|fractal_dimension_se|radius_worst|texture_worst|perimeter_worst|area_worst|smoothness_worst|compactness_worst|concavity_worst|concave points_worst|symmetry_worst|fractal_dimension_worst|\n",
            "+--------+---------+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+\n",
            "|  842302|        M|      17.99|       10.38|         122.8|   1001.0|         0.1184|          0.2776|        0.3001|             0.1471|       0.2419|               0.07871|    1.095|    0.9053|       8.589|  153.4|     0.006399|       0.04904|     0.05373|          0.01587|    0.03003|            0.006193|       25.38|        17.33|          184.6|    2019.0|          0.1622|           0.6656|         0.7119|              0.2654|        0.4601|                 0.1189|\n",
            "|  842517|        M|      20.57|       17.77|         132.9|   1326.0|        0.08474|         0.07864|        0.0869|            0.07017|       0.1812|               0.05667|   0.5435|    0.7339|       3.398|  74.08|     0.005225|       0.01308|      0.0186|           0.0134|    0.01389|            0.003532|       24.99|        23.41|          158.8|    1956.0|          0.1238|           0.1866|         0.2416|               0.186|         0.275|                0.08902|\n",
            "|84300903|        M|      19.69|       21.25|         130.0|   1203.0|         0.1096|          0.1599|        0.1974|             0.1279|       0.2069|               0.05999|   0.7456|    0.7869|       4.585|  94.03|      0.00615|       0.04006|     0.03832|          0.02058|     0.0225|            0.004571|       23.57|        25.53|          152.5|    1709.0|          0.1444|           0.4245|         0.4504|               0.243|        0.3613|                0.08758|\n",
            "|84348301|        M|      11.42|       20.38|         77.58|    386.1|         0.1425|          0.2839|        0.2414|             0.1052|       0.2597|               0.09744|   0.4956|     1.156|       3.445|  27.23|      0.00911|       0.07458|     0.05661|          0.01867|    0.05963|            0.009208|       14.91|         26.5|          98.87|     567.7|          0.2098|           0.8663|         0.6869|              0.2575|        0.6638|                  0.173|\n",
            "|84358402|        M|      20.29|       14.34|         135.1|   1297.0|         0.1003|          0.1328|         0.198|             0.1043|       0.1809|               0.05883|   0.7572|    0.7813|       5.438|  94.44|      0.01149|       0.02461|     0.05688|          0.01885|    0.01756|            0.005115|       22.54|        16.67|          152.2|    1575.0|          0.1374|            0.205|            0.4|              0.1625|        0.2364|                0.07678|\n",
            "+--------+---------+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos el esquema para poder ver cuales atributos son importantes pra nuestra prediccion"
      ],
      "metadata": {
        "id": "3C6rj7Z_Ezeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimimos el esquema con los tipos de datos que se infirieron\n",
        "df_spark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHfe33laHytf",
        "outputId": "8a2c162b-f1d5-40ee-d0fe-e8108a0a57ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- diagnosis: string (nullable = true)\n",
            " |-- radius_mean: double (nullable = true)\n",
            " |-- texture_mean: double (nullable = true)\n",
            " |-- perimeter_mean: double (nullable = true)\n",
            " |-- area_mean: double (nullable = true)\n",
            " |-- smoothness_mean: double (nullable = true)\n",
            " |-- compactness_mean: double (nullable = true)\n",
            " |-- concavity_mean: double (nullable = true)\n",
            " |-- concave points_mean: double (nullable = true)\n",
            " |-- symmetry_mean: double (nullable = true)\n",
            " |-- fractal_dimension_mean: double (nullable = true)\n",
            " |-- radius_se: double (nullable = true)\n",
            " |-- texture_se: double (nullable = true)\n",
            " |-- perimeter_se: double (nullable = true)\n",
            " |-- area_se: double (nullable = true)\n",
            " |-- smoothness_se: double (nullable = true)\n",
            " |-- compactness_se: double (nullable = true)\n",
            " |-- concavity_se: double (nullable = true)\n",
            " |-- concave points_se: double (nullable = true)\n",
            " |-- symmetry_se: double (nullable = true)\n",
            " |-- fractal_dimension_se: double (nullable = true)\n",
            " |-- radius_worst: double (nullable = true)\n",
            " |-- texture_worst: double (nullable = true)\n",
            " |-- perimeter_worst: double (nullable = true)\n",
            " |-- area_worst: double (nullable = true)\n",
            " |-- smoothness_worst: double (nullable = true)\n",
            " |-- compactness_worst: double (nullable = true)\n",
            " |-- concavity_worst: double (nullable = true)\n",
            " |-- concave points_worst: double (nullable = true)\n",
            " |-- symmetry_worst: double (nullable = true)\n",
            " |-- fractal_dimension_worst: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a eliminar la columna id porque no es importante para la prediccion que buscamos\n"
      ],
      "metadata": {
        "id": "o17Y5YzkE9kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = df_spark.drop(\"id\")"
      ],
      "metadata": {
        "id": "gyfgyBFAH1dZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las variables categoricas las pasamos a numericas porque nuestro modelo no puede procesar strings"
      ],
      "metadata": {
        "id": "3o5ZZqE8HIAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol='diagnosis', outputCol='diagnosis#')\n",
        "indexer_fitted = indexer.fit(df_spark)\n",
        "df_indexed = indexer_fitted.transform(df_spark)\n",
        "df_indexed = df_indexed.drop(\"diagnosis\")\n",
        "df_indexed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSX1LwNnIDFN",
        "outputId": "4f8586dd-f572-4a58-9803-d5581eb64b01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+----------+\n",
            "|radius_mean|texture_mean|perimeter_mean|area_mean|smoothness_mean|compactness_mean|concavity_mean|concave points_mean|symmetry_mean|fractal_dimension_mean|radius_se|texture_se|perimeter_se|area_se|smoothness_se|compactness_se|concavity_se|concave points_se|symmetry_se|fractal_dimension_se|radius_worst|texture_worst|perimeter_worst|area_worst|smoothness_worst|compactness_worst|concavity_worst|concave points_worst|symmetry_worst|fractal_dimension_worst|diagnosis#|\n",
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+----------+\n",
            "|      17.99|       10.38|         122.8|   1001.0|         0.1184|          0.2776|        0.3001|             0.1471|       0.2419|               0.07871|    1.095|    0.9053|       8.589|  153.4|     0.006399|       0.04904|     0.05373|          0.01587|    0.03003|            0.006193|       25.38|        17.33|          184.6|    2019.0|          0.1622|           0.6656|         0.7119|              0.2654|        0.4601|                 0.1189|       1.0|\n",
            "|      20.57|       17.77|         132.9|   1326.0|        0.08474|         0.07864|        0.0869|            0.07017|       0.1812|               0.05667|   0.5435|    0.7339|       3.398|  74.08|     0.005225|       0.01308|      0.0186|           0.0134|    0.01389|            0.003532|       24.99|        23.41|          158.8|    1956.0|          0.1238|           0.1866|         0.2416|               0.186|         0.275|                0.08902|       1.0|\n",
            "|      19.69|       21.25|         130.0|   1203.0|         0.1096|          0.1599|        0.1974|             0.1279|       0.2069|               0.05999|   0.7456|    0.7869|       4.585|  94.03|      0.00615|       0.04006|     0.03832|          0.02058|     0.0225|            0.004571|       23.57|        25.53|          152.5|    1709.0|          0.1444|           0.4245|         0.4504|               0.243|        0.3613|                0.08758|       1.0|\n",
            "|      11.42|       20.38|         77.58|    386.1|         0.1425|          0.2839|        0.2414|             0.1052|       0.2597|               0.09744|   0.4956|     1.156|       3.445|  27.23|      0.00911|       0.07458|     0.05661|          0.01867|    0.05963|            0.009208|       14.91|         26.5|          98.87|     567.7|          0.2098|           0.8663|         0.6869|              0.2575|        0.6638|                  0.173|       1.0|\n",
            "|      20.29|       14.34|         135.1|   1297.0|         0.1003|          0.1328|         0.198|             0.1043|       0.1809|               0.05883|   0.7572|    0.7813|       5.438|  94.44|      0.01149|       0.02461|     0.05688|          0.01885|    0.01756|            0.005115|       22.54|        16.67|          152.2|    1575.0|          0.1374|            0.205|            0.4|              0.1625|        0.2364|                0.07678|       1.0|\n",
            "|      12.45|        15.7|         82.57|    477.1|         0.1278|            0.17|        0.1578|            0.08089|       0.2087|               0.07613|   0.3345|    0.8902|       2.217|  27.19|      0.00751|       0.03345|     0.03672|          0.01137|    0.02165|            0.005082|       15.47|        23.75|          103.4|     741.6|          0.1791|           0.5249|         0.5355|              0.1741|        0.3985|                 0.1244|       1.0|\n",
            "|      18.25|       19.98|         119.6|   1040.0|        0.09463|           0.109|        0.1127|              0.074|       0.1794|               0.05742|   0.4467|    0.7732|        3.18|  53.91|     0.004314|       0.01382|     0.02254|          0.01039|    0.01369|            0.002179|       22.88|        27.66|          153.2|    1606.0|          0.1442|           0.2576|         0.3784|              0.1932|        0.3063|                0.08368|       1.0|\n",
            "|      13.71|       20.83|          90.2|    577.9|         0.1189|          0.1645|       0.09366|            0.05985|       0.2196|               0.07451|   0.5835|     1.377|       3.856|  50.96|     0.008805|       0.03029|     0.02488|          0.01448|    0.01486|            0.005412|       17.06|        28.14|          110.6|     897.0|          0.1654|           0.3682|         0.2678|              0.1556|        0.3196|                 0.1151|       1.0|\n",
            "|       13.0|       21.82|          87.5|    519.8|         0.1273|          0.1932|        0.1859|            0.09353|        0.235|               0.07389|   0.3063|     1.002|       2.406|  24.32|     0.005731|       0.03502|     0.03553|          0.01226|    0.02143|            0.003749|       15.49|        30.73|          106.2|     739.3|          0.1703|           0.5401|          0.539|               0.206|        0.4378|                 0.1072|       1.0|\n",
            "|      12.46|       24.04|         83.97|    475.9|         0.1186|          0.2396|        0.2273|            0.08543|        0.203|               0.08243|   0.2976|     1.599|       2.039|  23.94|     0.007149|       0.07217|     0.07743|          0.01432|    0.01789|             0.01008|       15.09|        40.68|          97.65|     711.4|          0.1853|            1.058|          1.105|               0.221|        0.4366|                 0.2075|       1.0|\n",
            "|      16.02|       23.24|         102.7|    797.8|        0.08206|         0.06669|       0.03299|            0.03323|       0.1528|               0.05697|   0.3795|     1.187|       2.466|  40.51|     0.004029|      0.009269|     0.01101|         0.007591|     0.0146|            0.003042|       19.19|        33.88|          123.8|    1150.0|          0.1181|           0.1551|         0.1459|             0.09975|        0.2948|                0.08452|       1.0|\n",
            "|      15.78|       17.89|         103.6|    781.0|         0.0971|          0.1292|       0.09954|            0.06606|       0.1842|               0.06082|   0.5058|    0.9849|       3.564|  54.16|     0.005771|       0.04061|     0.02791|          0.01282|    0.02008|            0.004144|       20.42|        27.28|          136.5|    1299.0|          0.1396|           0.5609|         0.3965|               0.181|        0.3792|                 0.1048|       1.0|\n",
            "|      19.17|        24.8|         132.4|   1123.0|         0.0974|          0.2458|        0.2065|             0.1118|       0.2397|                 0.078|   0.9555|     3.568|       11.07|  116.2|     0.003139|       0.08297|      0.0889|           0.0409|    0.04484|             0.01284|       20.96|        29.94|          151.7|    1332.0|          0.1037|           0.3903|         0.3639|              0.1767|        0.3176|                 0.1023|       1.0|\n",
            "|      15.85|       23.95|         103.7|    782.7|        0.08401|          0.1002|       0.09938|            0.05364|       0.1847|               0.05338|   0.4033|     1.078|       2.903|  36.58|     0.009769|       0.03126|     0.05051|          0.01992|    0.02981|            0.003002|       16.84|        27.66|          112.0|     876.5|          0.1131|           0.1924|         0.2322|              0.1119|        0.2809|                0.06287|       1.0|\n",
            "|      13.73|       22.61|          93.6|    578.3|         0.1131|          0.2293|        0.2128|            0.08025|       0.2069|               0.07682|   0.2121|     1.169|       2.061|  19.21|     0.006429|       0.05936|     0.05501|          0.01628|    0.01961|            0.008093|       15.03|        32.01|          108.8|     697.7|          0.1651|           0.7725|         0.6943|              0.2208|        0.3596|                 0.1431|       1.0|\n",
            "|      14.54|       27.54|         96.73|    658.8|         0.1139|          0.1595|        0.1639|            0.07364|       0.2303|               0.07077|     0.37|     1.033|       2.879|  32.55|     0.005607|        0.0424|     0.04741|           0.0109|    0.01857|            0.005466|       17.46|        37.13|          124.1|     943.2|          0.1678|           0.6577|         0.7026|              0.1712|        0.4218|                 0.1341|       1.0|\n",
            "|      14.68|       20.13|         94.74|    684.5|        0.09867|           0.072|       0.07395|            0.05259|       0.1586|               0.05922|   0.4727|      1.24|       3.195|   45.4|     0.005718|       0.01162|     0.01998|          0.01109|     0.0141|            0.002085|       19.07|        30.88|          123.4|    1138.0|          0.1464|           0.1871|         0.2914|              0.1609|        0.3029|                0.08216|       1.0|\n",
            "|      16.13|       20.68|         108.1|    798.8|          0.117|          0.2022|        0.1722|             0.1028|       0.2164|               0.07356|   0.5692|     1.073|       3.854|  54.18|     0.007026|       0.02501|     0.03188|          0.01297|    0.01689|            0.004142|       20.96|        31.48|          136.8|    1315.0|          0.1789|           0.4233|         0.4784|              0.2073|        0.3706|                 0.1142|       1.0|\n",
            "|      19.81|       22.15|         130.0|   1260.0|        0.09831|          0.1027|        0.1479|            0.09498|       0.1582|               0.05395|   0.7582|     1.017|       5.865|  112.4|     0.006494|       0.01893|     0.03391|          0.01521|    0.01356|            0.001997|       27.32|        30.88|          186.8|    2398.0|          0.1512|            0.315|         0.5372|              0.2388|        0.2768|                0.07615|       1.0|\n",
            "|      13.54|       14.36|         87.46|    566.3|        0.09779|         0.08129|       0.06664|            0.04781|       0.1885|               0.05766|   0.2699|    0.7886|       2.058|  23.56|     0.008462|        0.0146|     0.02387|          0.01315|     0.0198|              0.0023|       15.11|        19.26|           99.7|     711.2|           0.144|           0.1773|          0.239|              0.1288|        0.2977|                0.07259|       0.0|\n",
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+---------+----------+------------+-------+-------------+--------------+------------+-----------------+-----------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos los datos en conjuntos de entrenamiento y prueba con el fin de evaluar el rendimiento de nuestro modelo después de ser entrenado. Asignamos el 70% de los datos al conjunto de entrenamiento para garantizar una cantidad adecuada de ejemplos de entrenamiento, y el restante se destina al conjunto de prueba, ya que contamos con suficientes instancias para utilizar esta configuración."
      ],
      "metadata": {
        "id": "4wOgwBtGHlj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos un split de los datos en train y test\n",
        "(train, test) = df_indexed.randomSplit([0.7, 0.3], seed=42)"
      ],
      "metadata": {
        "id": "kfGaUe7LIGP9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformamos nuestros datos en un vector ensamblado para que la biblioteca pyspark.ml pueda procesarlos, y utilizamos todas las variables restantes, ya que son pertinentes para la tarea de clasificación que estamos llevando a cabo."
      ],
      "metadata": {
        "id": "IRAhlKZEHzuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasar nuestros datos a un vector assembler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "cols = [\"radius_mean\", \"texture_mean\",\n",
        "        \"perimeter_mean\", \"area_mean\",\n",
        "        \"smoothness_mean\", \"compactness_mean\",\n",
        "        \"concavity_mean\", \"concave points_mean\",\n",
        "        \"symmetry_mean\", \"fractal_dimension_mean\",\n",
        "        \"radius_se\", \"texture_se\", \"perimeter_se\",\n",
        "        \"area_se\", \"smoothness_se\", \"compactness_se\",\n",
        "        \"concavity_se\", \"concave points_se\",\n",
        "        \"symmetry_se\", \"fractal_dimension_se\",\n",
        "        \"radius_worst\", \"texture_worst\", \"perimeter_worst\",\n",
        "        \"area_worst\", \"smoothness_worst\",\n",
        "        \"compactness_worst\", \"concavity_worst\",\n",
        "        \"concave points_worst\", \"symmetry_worst\",\n",
        "        \"fractal_dimension_worst\"]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=cols,\n",
        "    outputCol=\"features\")\n",
        "\n",
        "transformed_train = assembler.transform(train)\n",
        "transformed_test = assembler.transform(test)\n",
        "\n",
        "# Droppeamos columnas innecesarias\n",
        "transformed_train = transformed_train.drop(*cols)\n",
        "transformed_test = transformed_test.drop(*cols)\n",
        "transformed_train.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0vZeoJQINH_",
        "outputId": "228fbcf5-568e-47bf-c3ab-e25f4a8c4029"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|diagnosis#|            features|\n",
            "+----------+--------------------+\n",
            "|       0.0|[6.981,13.43,43.7...|\n",
            "|       0.0|[7.691,25.44,48.3...|\n",
            "|       0.0|[7.76,24.54,47.92...|\n",
            "|       0.0|[8.196,16.84,51.7...|\n",
            "|       0.0|[8.219,20.7,53.27...|\n",
            "|       0.0|[8.597,18.6,54.09...|\n",
            "|       0.0|[8.671,14.45,54.4...|\n",
            "|       0.0|[8.726,15.83,55.8...|\n",
            "|       0.0|[8.734,16.84,55.2...|\n",
            "|       0.0|[9.0,14.4,56.36,2...|\n",
            "|       0.0|[9.029,17.33,58.7...|\n",
            "|       0.0|[9.042,18.9,60.07...|\n",
            "|       0.0|[9.268,12.87,61.4...|\n",
            "|       0.0|[9.333,21.94,59.0...|\n",
            "|       0.0|[9.423,27.88,59.2...|\n",
            "|       0.0|[9.436,18.32,59.8...|\n",
            "|       0.0|[9.465,21.01,60.1...|\n",
            "|       0.0|[9.667,18.49,61.4...|\n",
            "|       0.0|[9.676,13.14,64.1...|\n",
            "|       0.0|[9.731,15.34,63.7...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que planeamos utilizar pyspark.ml, necesitamos asegurarnos de que nuestros vectores estén en un formato compatible."
      ],
      "metadata": {
        "id": "vBRLAmtxH1jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib import linalg as mllib_linalg\n",
        "from pyspark.ml import linalg as ml_linalg\n",
        "\n",
        "def as_old(v):\n",
        "    if isinstance(v, ml_linalg.SparseVector):\n",
        "        return mllib_linalg.SparseVector(v.size, v.indices, v.values)\n",
        "    if isinstance(v, ml_linalg.DenseVector):\n",
        "        return mllib_linalg.DenseVector(v.values)\n",
        "    raise ValueError(\"Unsupported type {0}\".format(type(v)))"
      ],
      "metadata": {
        "id": "9VQCas-ZIThH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para concluir, transformamos nuestros vectores en puntos etiquetados (labeled points) y los incluimos en un RDD, ya que MLlib solo puede procesar RDDs."
      ],
      "metadata": {
        "id": "Wj1VahHfInaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasar nuestros features a un Labeled Point y que MLlib lo pueda procesar\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "train_dataset = (transformed_train.select(col(\"diagnosis#\").alias(\"label\"), col(\"features\"))\\\n",
        "                  .rdd.map(lambda row: LabeledPoint(row.label, as_old(row.features))))\n",
        "\n",
        "\n",
        "test_dataset = (transformed_test.select(col(\"diagnosis#\").alias(\"label\"), col(\"features\"))\\\n",
        "                  .rdd.map(lambda row: LabeledPoint(row.label, as_old(row.features))))"
      ],
      "metadata": {
        "id": "8jeKFdCEIUd4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegimos emplear un árbol de decisión debido a que, en problemas de clasificación, los árboles suelen ser más efectivos."
      ],
      "metadata": {
        "id": "Now7coGCIpSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Como el problema con el que nos encontramos es de clasificación aplicaremos un decision tree con MLlib de pyspark\n",
        "from pyspark.mllib.tree import DecisionTree\n",
        "from pyspark.mllib.tree import DecisionTreeModel\n",
        "\n",
        "numClasses = 2\n",
        "categoricalFeaturesInfo = {}\n",
        "impurity = \"gini\"\n",
        "\n",
        "# transformamos el dataframe a un rdd y poder usar MLlib\n",
        "model = DecisionTree.trainClassifier(train_dataset, numClasses,\n",
        "                                     categoricalFeaturesInfo, impurity)"
      ],
      "metadata": {
        "id": "wEIx5qqVIYT6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos la eficacia de nuestro modelo utilizando los datos de prueba y calculamos el error, el cual resulta ser bastante bajo, alrededor del 5%."
      ],
      "metadata": {
        "id": "AfuZiSdNI79v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset.map(lambda x: x.features))\n",
        "labelsAndPredictions = test_dataset.map(lambda lp: lp.label).zip(predictions)\n",
        "testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(test_dataset.count())\n",
        "print('Test Error = ' + str(testErr))\n",
        "print('Learned classification tree model:')\n",
        "print(model.toDebugString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZAzBgEnIc6E",
        "outputId": "49fe92fc-1793-489b-fe00-30ca4f1b9278"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.06293706293706294\n",
            "Learned classification tree model:\n",
            "DecisionTreeModel classifier of depth 5 with 27 nodes\n",
            "  If (feature 23 <= 868.2)\n",
            "   If (feature 27 <= 0.13215)\n",
            "    If (feature 10 <= 1.0085)\n",
            "     If (feature 27 <= 0.11065)\n",
            "      Predict: 0.0\n",
            "     Else (feature 27 > 0.11065)\n",
            "      If (feature 9 <= 0.05648)\n",
            "       Predict: 1.0\n",
            "      Else (feature 9 > 0.05648)\n",
            "       Predict: 0.0\n",
            "    Else (feature 10 > 1.0085)\n",
            "     Predict: 1.0\n",
            "   Else (feature 27 > 0.13215)\n",
            "    If (feature 21 <= 27.205)\n",
            "     If (feature 4 <= 0.12215000000000001)\n",
            "      If (feature 1 <= 20.675)\n",
            "       Predict: 0.0\n",
            "      Else (feature 1 > 20.675)\n",
            "       Predict: 1.0\n",
            "     Else (feature 4 > 0.12215000000000001)\n",
            "      Predict: 1.0\n",
            "    Else (feature 21 > 27.205)\n",
            "     If (feature 8 <= 0.15339999999999998)\n",
            "      Predict: 0.0\n",
            "     Else (feature 8 > 0.15339999999999998)\n",
            "      Predict: 1.0\n",
            "  Else (feature 23 > 868.2)\n",
            "   If (feature 1 <= 14.975000000000001)\n",
            "    If (feature 4 <= 0.09582)\n",
            "     Predict: 0.0\n",
            "    Else (feature 4 > 0.09582)\n",
            "     Predict: 1.0\n",
            "   Else (feature 1 > 14.975000000000001)\n",
            "    If (feature 8 <= 0.15025)\n",
            "     If (feature 0 <= 17.405)\n",
            "      Predict: 0.0\n",
            "     Else (feature 0 > 17.405)\n",
            "      Predict: 1.0\n",
            "    Else (feature 8 > 0.15025)\n",
            "     Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos nuestro modelo para cargarlo después, en caso de ser necesario\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "model.save(sc, \"BC_ClassificationModel.dt\")\n",
        "sameModel = DecisionTreeModel.load(sc, \"BC_ClassificationModel.dt\")"
      ],
      "metadata": {
        "id": "reGlu19II7qy"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}